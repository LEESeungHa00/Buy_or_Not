import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import statsmodels.api as sm
import io
from datetime import datetime, timedelta

# êµ¬ê¸€ ì‹œíŠ¸ API ì—°ë™ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import gspread
from google.oauth2 import service_account

# ì„¤ì •: í˜ì´ì§€ ì œëª© ë° ë ˆì´ì•„ì›ƒ
st.set_page_config(
    page_title="Data-Driven_Direction",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'df_imports' not in st.session_state:
    st.session_state.df_imports = pd.DataFrame()
if 'df_naver' not in st.session_state:
    st.session_state.df_naver = pd.DataFrame()
if 'df_tds' not in st.session_state:
    st.session_state.df_tds = pd.DataFrame()
if 'df_combined' not in st.session_state:
    st.session_state.df_combined = pd.DataFrame()
if 'selected_hscodes' not in st.session_state:
    st.session_state.selected_hscodes = []

st.title("ğŸ§­ Compass : Data-Driven Direction")

st.markdown("""
<style>
.stTabs [data-baseweb="tab-list"] button [data-testid="stMarkdownContainer"] p {
    font-size: 1.2rem;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)

# -----------------
# êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ í•¨ìˆ˜
# -----------------
@st.cache_resource(ttl=3600)
def get_google_sheet_client():
    """
    Streamlit secretsë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ê¸€ ì‹œíŠ¸ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¸ì¦í•˜ê³  ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    ì‹¤ì œ Streamlit Cloud í™˜ê²½ì—ì„œ secretsì— ì„œë¹„ìŠ¤ ê³„ì • JSONì´ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨.
    """
    try:
        credentials = service_account.Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=["https://www.googleapis.com/auth/spreadsheets"]
        )
        gc = gspread.authorize(credentials)
        return gc
    except Exception as e:
        st.error(f"êµ¬ê¸€ ì‹œíŠ¸ ì¸ì¦ ì˜¤ë¥˜: {e}")
        return None
        
def normalize_hscode(hscode_series):
    """
    HSì½”ë“œë¥¼ 10ìë¦¬ ë¬¸ìì—´ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.
    """
    return hscode_series.astype(str).str.strip().str.zfill(10)

def read_google_sheet(sheet_name):
    """
    ì§€ì •ëœ êµ¬ê¸€ ì‹œíŠ¸ì˜ ì›Œí¬ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    gc = get_google_sheet_client()
    if gc:
        try:
            sh = gc.open_by_url("https://docs.google.com/spreadsheets/d/12YdcKX3nvaNfFWYkJApRnoKAQnjCeR09AGRJ6rBiOuM/edit?gid=0#gid=0")
            worksheet = sh.worksheet(sheet_name)
            
            all_data = worksheet.get_all_values()
            if not all_data:
                return pd.DataFrame()
            
            headers = all_data[0]
            seen = {}
            for i, header in enumerate(headers):
                if not header:
                    headers[i] = f'Unnamed_{i}'
                elif header in seen:
                    headers[i] = f'{header}_{seen[header]}'
                    seen[header] += 1
                else:
                    seen[header] = 1

            data = all_data[1:]
            df = pd.DataFrame(data, columns=headers)
            
            # ë°ì´í„° ì •ì œ ë° íƒ€ì… ë³€í™˜
            if sheet_name == 'ë„¤ì´ë²„ ë°ì´í„°ë©':
                if 'ì»¤í”¼' in df.columns:
                    df.rename(columns={'ì»¤í”¼': 'ê²€ìƒ‰ëŸ‰'}, inplace=True)
                df['ê²€ìƒ‰ëŸ‰'] = pd.to_numeric(df['ê²€ìƒ‰ëŸ‰'], errors='coerce')
            elif sheet_name == 'TDS':
                if 'Detailed HS-CODE' in df.columns:
                    df.rename(columns={'Detailed HS-CODE': 'HSì½”ë“œ'}, inplace=True)
                df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')
                df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
                if 'HSì½”ë“œ' in df.columns:
                    df['HSì½”ë“œ'] = normalize_hscode(df['HSì½”ë“œ'])
            elif sheet_name == 'ê´€ì„¸ì²­':
                df['ìˆ˜ì… ì¤‘ëŸ‰'] = pd.to_numeric(df['ìˆ˜ì… ì¤‘ëŸ‰'], errors='coerce')
                df['ìˆ˜ì… ê¸ˆì•¡'] = pd.to_numeric(df['ìˆ˜ì… ê¸ˆì•¡'], errors='coerce')
                if 'HSì½”ë“œ' in df.columns:
                    df['HSì½”ë“œ'] = normalize_hscode(df['HSì½”ë“œ'])

            return df
        except Exception as e:
            st.error(f"'{sheet_name}' ì›Œí¬ì‹œíŠ¸ ì½ê¸° ì˜¤ë¥˜: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

# -----------------
# íŒŒì¼ ì—…ë¡œë“œ ë° ë°ì´í„° ì²˜ë¦¬
# -----------------
st.sidebar.header("ë°ì´í„° ì—…ë¡œë“œ ë° ê°€ì ¸ì˜¤ê¸°")
uploaded_imports = st.sidebar.file_uploader("1. ê´€ì„¸ì²­ ë°ì´í„° (.csv)", type="csv", key="imports")
uploaded_naver = st.sidebar.file_uploader("2. ë„¤ì´ë²„ ë°ì´í„°ë© (.csv)", type="csv", key="naver")
uploaded_tds = st.sidebar.file_uploader("3. íŠ¸ë¦¿ì§€ ë°ì´í„° (.csv)", type="csv", key="tds")

def load_data():
    if uploaded_imports:
        try:
            df = pd.read_csv(uploaded_imports)
            if 'ê¸°ê°„' not in df.columns:
                if 'ë…„' in df.columns and 'ì›”' in df.columns:
                    df['ê¸°ê°„'] = df['ë…„'].astype(str) + '.' + df['ì›”'].astype(str).str.zfill(2)
            # ìˆ˜ì…ëŸ‰, ìˆ˜ì…ê¸ˆì•¡ ìˆ«ìí˜• ë³€í™˜
            df['ìˆ˜ì… ì¤‘ëŸ‰'] = pd.to_numeric(df['ìˆ˜ì… ì¤‘ëŸ‰'], errors='coerce')
            df['ìˆ˜ì… ê¸ˆì•¡'] = pd.to_numeric(df['ìˆ˜ì… ê¸ˆì•¡'], errors='coerce')
            # HSì½”ë“œ ì •ê·œí™”
            if 'HSì½”ë“œ' in df.columns:
                df['HSì½”ë“œ'] = normalize_hscode(df['HSì½”ë“œ'])

            st.session_state.df_imports = pd.concat([st.session_state.df_imports, df], ignore_index=True)
            st.sidebar.success("ê´€ì„¸ì²­ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            st.sidebar.error(f"ê´€ì„¸ì²­ CSV íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")

    if uploaded_naver:
        try:
            # ë„¤ì´ë²„ ë°ì´í„°ë© CSV íŒŒì¼ì€ ì²« ë²ˆì§¸ í–‰ì— í—¤ë”ê°€ ìˆìŠµë‹ˆë‹¤.
            df = pd.read_csv(uploaded_naver, skiprows=6)
            
            # 'ì»¤í”¼'ë¼ëŠ” ì»¬ëŸ¼ì„ 'ê²€ìƒ‰ëŸ‰'ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
            if 'ì»¤í”¼' in df.columns:
                df.rename(columns={'ì»¤í”¼': 'ê²€ìƒ‰ëŸ‰'}, inplace=True)
            
            # ê²€ìƒ‰ëŸ‰ ì»¬ëŸ¼ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            df['ê²€ìƒ‰ëŸ‰'] = pd.to_numeric(df['ê²€ìƒ‰ëŸ‰'], errors='coerce')
            
            st.session_state.df_naver = pd.concat([st.session_state.df_naver, df], ignore_index=True)
            st.sidebar.success("ë„¤ì´ë²„ ë°ì´í„°ë© ì—…ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            st.sidebar.error(f"ë„¤ì´ë²„ ë°ì´í„°ë© CSV íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")

    if uploaded_tds:
        try:
            df_raw = uploaded_tds.getvalue().decode("utf-8")
            df = pd.read_csv(io.StringIO(df_raw), header=None)
            
            headers = df.iloc[0].tolist()
            seen = {}
            new_headers = []
            for i, header in enumerate(headers):
                if not isinstance(header, str) or not header:
                    new_header = f'Unnamed_{i}'
                elif header in seen:
                    seen[header] += 1
                    new_header = f'{header}_{seen[header]}'
                else:
                    seen[header] = 1
                    new_header = header
                new_headers.append(new_header)
            
            df.columns = new_headers
            df = df.iloc[1:].reset_index(drop=True)
            
            # TDS ë°ì´í„°ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë³€í™˜
            if 'Detailed HS-CODE' in df.columns:
                df.rename(columns={'Detailed HS-CODE': 'HSì½”ë“œ'}, inplace=True)
            if 'Volume' in df.columns:
                df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')
            if 'Value' in df.columns:
                df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
            # HSì½”ë“œ ì •ê·œí™”
            if 'HSì½”ë“œ' in df.columns:
                df['HSì½”ë“œ'] = normalize_hscode(df['HSì½”ë“œ'])

            st.session_state.df_tds = pd.concat([st.session_state.df_tds, df], ignore_index=True)
            st.sidebar.success("TDS ì—…ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            st.sidebar.error(f"TDS CSV íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")

if st.sidebar.button("ë°ì´í„° ì—…ë¡œë“œ ë° ê°€ì ¸ì˜¤ê¸°"):
    load_data()
    st.session_state.df_imports = read_google_sheet("ê´€ì„¸ì²­")
    st.session_state.df_naver = read_google_sheet("ë„¤ì´ë²„ ë°ì´í„°ë©")
    st.session_state.df_tds = read_google_sheet("TDS")
    if not st.session_state.df_imports.empty: st.sidebar.success("ê´€ì„¸ì²­ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
    if not st.session_state.df_naver.empty: st.sidebar.success("ë„¤ì´ë²„ ë°ì´í„°ë© ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
    if not st.session_state.df_tds.empty: st.sidebar.success("TDS ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")

if st.session_state.df_imports.empty or st.session_state.df_tds.empty or st.session_state.df_naver.empty:
    st.warning("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ **ë°ì´í„° ì—…ë¡œë“œ ë° ê°€ì ¸ì˜¤ê¸°** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
else:
    # HSì½”ë“œ ëª©ë¡ ìƒì„± ë° ì „ì²˜ë¦¬
    df_imports_hscodes = st.session_state.df_imports[['HSì½”ë“œ', 'í’ˆëª©ëª…']].dropna()
    df_tds_hscodes = st.session_state.df_tds.rename(columns={'Product Description': 'í’ˆëª©ëª…'})[['HSì½”ë“œ', 'í’ˆëª©ëª…']].dropna()
    
    all_hscodes = pd.concat([df_imports_hscodes, df_tds_hscodes]).drop_duplicates(subset='HSì½”ë“œ').sort_values(by='HSì½”ë“œ').reset_index(drop=True)
    
    # 10ìë¦¬ ìˆ«ì HSì½”ë“œë§Œ í•„í„°ë§
    all_hscodes = all_hscodes[all_hscodes['HSì½”ë“œ'].str.strip().str.len() == 10]
    all_hscodes['display_name'] = all_hscodes['HSì½”ë“œ'].astype(str) + ' - ' + all_hscodes['í’ˆëª©ëª…']
    
    hscode_options = all_hscodes['display_name'].tolist()

    st.session_state.selected_hscodes = st.sidebar.multiselect(
        "ë¶„ì„í•  HSì½”ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=hscode_options,
        default=hscode_options[:2] if len(hscode_options) > 1 else hscode_options
    )

    selected_codes = [s.split(' - ')[0] for s in st.session_state.selected_hscodes]

    if not selected_codes:
        st.warning("ë¶„ì„ì„ ìœ„í•´ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ HSì½”ë“œë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        # ê¸°ê°„ ì„ íƒ ìŠ¬ë¼ì´ë”
        min_date_ts = pd.to_datetime('2020-01-01')
        max_date_ts = pd.to_datetime(datetime.now())
        start_date, end_date = st.sidebar.slider(
            "ë¶„ì„ ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”",
            min_value=min_date_ts.to_pydatetime(),
            max_value=max_date_ts.to_pydatetime(),
            value=(min_date_ts.to_pydatetime(), max_date_ts.to_pydatetime()),
            format="YYYY-MM-DD"
        )
        
        with st.spinner('ë°ì´í„°ë¥¼ í†µí•©í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            try:
                # ê´€ì„¸ì²­ê³¼ TDS ë°ì´í„° í†µí•©
                df_imports_filtered = st.session_state.df_imports[
                    st.session_state.df_imports['HSì½”ë“œ'].astype(str).isin(selected_codes)
                ].copy()
                df_imports_filtered['ê¸°ê°„'] = pd.to_datetime(df_imports_filtered['ê¸°ê°„'], format='%Y.%m', errors='coerce')
                
                df_tds_filtered = st.session_state.df_tds[
                    st.session_state.df_tds['HSì½”ë“œ'].astype(str).isin(selected_codes)
                ].copy()
                df_tds_filtered['Date'] = pd.to_datetime(df_tds_filtered['Date'], errors='coerce')
                
                # 'ê¸°ê°„'ê³¼ 'Date' ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë³‘í•©
                df_combined_imports_tds = pd.concat([
                    df_imports_filtered.rename(columns={'ìˆ˜ì… ì¤‘ëŸ‰': 'Volume', 'ìˆ˜ì… ê¸ˆì•¡': 'Value', 'ê¸°ê°„': 'Date', 'êµ­ê°€': 'Origin Country'}),
                    df_tds_filtered
                ], ignore_index=True)
                
                # ê¸°ê°„ í•„í„°ë§
                df_combined_imports_tds['Date'] = pd.to_datetime(df_combined_imports_tds['Date'], errors='coerce')
                df_combined_imports_tds.dropna(subset=['Date'], inplace=True)
                df_combined_imports_tds = df_combined_imports_tds[
                    (df_combined_imports_tds['Date'] >= pd.Timestamp(start_date)) & 
                    (df_combined_imports_tds['Date'] <= pd.Timestamp(end_date))
                ]
                
                # ì›”ë³„ë¡œ ë°ì´í„° ê·¸ë£¹í™”
                df_combined_monthly = df_combined_imports_tds.groupby(
                    pd.Grouper(key='Date', freq='M')
                ).agg({
                    'Volume': 'sum',
                    'Value': 'sum'
                }).reset_index().rename(columns={'Volume': 'ìˆ˜ì… ì¤‘ëŸ‰', 'Value': 'ìˆ˜ì… ê¸ˆì•¡'})
                
                # ë„¤ì´ë²„ ë°ì´í„°ë© ì „ì²˜ë¦¬
                df_naver_monthly = st.session_state.df_naver.copy()
                df_naver_monthly['ë‚ ì§œ'] = pd.to_datetime(df_naver_monthly['ë‚ ì§œ'], errors='coerce')
                df_naver_monthly.dropna(subset=['ë‚ ì§œ'], inplace=True)
                df_naver_monthly = df_naver_monthly[
                    (df_naver_monthly['ë‚ ì§œ'] >= pd.Timestamp(start_date)) & 
                    (df_naver_monthly['ë‚ ì§œ'] <= pd.Timestamp(end_date))
                ]
                df_naver_monthly = df_naver_monthly.groupby(
                    pd.Grouper(key='ë‚ ì§œ', freq='M')
                ).agg({'ê²€ìƒ‰ëŸ‰': 'mean'}).reset_index()

                # ìµœì¢… ë°ì´í„° í†µí•©
                df_combined = pd.merge(
                    df_combined_monthly,
                    df_naver_monthly,
                    left_on=df_combined_monthly['Date'].dt.strftime('%Y-%m'),
                    right_on=df_naver_monthly['ë‚ ì§œ'].dt.strftime('%Y-%m'),
                    how='outer'
                )
                
                # ì—´ ì´ë¦„ ë° ê²°ì¸¡ì¹˜ ì •ë¦¬
                df_combined.rename(columns={'key_0': 'ê¸°ê°„'}, inplace=True)
                df_combined.drop(['Date', 'ë‚ ì§œ'], axis=1, errors='ignore', inplace=True)
                df_combined['ìˆ˜ì… ì¤‘ëŸ‰'].fillna(0, inplace=True)
                df_combined['ìˆ˜ì… ê¸ˆì•¡'].fillna(0, inplace=True)
                df_combined['ê²€ìƒ‰ëŸ‰'].fillna(0, inplace=True)
                
                # TDSì—ì„œ ì˜¨ 'ê¸°ê°„' ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì œê±°
                if 'ê¸°ê°„_y' in df_combined.columns:
                    df_combined.drop('ê¸°ê°„_y', axis=1, inplace=True)

                st.session_state.df_combined = df_combined
                st.success("ë°ì´í„° í†µí•© ì™„ë£Œ!")
            except Exception as e:
                st.error(f"ë°ì´í„° í†µí•© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì„ íƒí•œ HSì½”ë“œì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ê±°ë‚˜, ì—…ë¡œë“œí•œ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”: {e}")

        # -----------------
        # íƒ­ êµ¬ì„±
        # -----------------
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ”® ì˜ˆì¸¡ ëª¨ë¸", "ğŸ“ˆ ìƒê´€ê´€ê³„ ë¶„ì„", "ğŸ—ƒï¸ ì›ë³¸ ë°ì´í„°"])

        with tab1:
            st.header("ì»¤í”¼ ì›ë‘ ì‹œì¥ ë™í–¥ ë¶„ì„")
            if not st.session_state.df_combined.empty and not st.session_state.df_combined['ìˆ˜ì… ì¤‘ëŸ‰'].sum() == 0:
                # KPI ì§€í‘œ
                col1, col2, col3 = st.columns(3)
                with col1:
                    total_volume = st.session_state.df_combined['ìˆ˜ì… ì¤‘ëŸ‰'].sum() / 1000000
                    st.metric("ì´ ìˆ˜ì…ëŸ‰ (ë°±ë§Œ kg)", f"{total_volume:,.2f}")
                with col2:
                    total_value = st.session_state.df_combined['ìˆ˜ì… ê¸ˆì•¡'].sum() / 1000000
                    st.metric("ì´ ìˆ˜ì…ê¸ˆì•¡ (ë°±ë§Œ $)", f"{total_value:,.2f}")
                with col3:
                    valid_data = st.session_state.df_combined[st.session_state.df_combined['ìˆ˜ì… ì¤‘ëŸ‰'] > 0]
                    avg_unit_price = (valid_data['ìˆ˜ì… ê¸ˆì•¡'] / valid_data['ìˆ˜ì… ì¤‘ëŸ‰']).mean()
                    st.metric("í‰ê·  ë‹¨ê°€ ($/kg)", f"{avg_unit_price:,.2f}" if not pd.isna(avg_unit_price) else "N/A")

                # ê·¸ë˜í”„: ìˆ˜ì…ëŸ‰, ìˆ˜ì…ê¸ˆì•¡, ê²€ìƒ‰ëŸ‰
                st.subheader("ê¸°ê°„ë³„ ìˆ˜ì…ëŸ‰ ë° ê²€ìƒ‰ëŸ‰ ì¶”ì´")
                
                fig1 = make_subplots(specs=[[{"secondary_y": True}]])

                # ìˆ˜ì…ëŸ‰ ê·¸ë˜í”„
                fig1.add_trace(
                    go.Scatter(
                        x=st.session_state.df_combined['ê¸°ê°„'], 
                        y=st.session_state.df_combined['ìˆ˜ì… ì¤‘ëŸ‰'], 
                        name='ìˆ˜ì… ì¤‘ëŸ‰'
                    ),
                    secondary_y=False,
                )

                # ê²€ìƒ‰ëŸ‰ ê·¸ë˜í”„
                fig1.add_trace(
                    go.Scatter(
                        x=st.session_state.df_combined['ê¸°ê°„'], 
                        y=st.session_state.df_combined['ê²€ìƒ‰ëŸ‰'], 
                        name='ê²€ìƒ‰ëŸ‰'
                    ),
                    secondary_y=True,
                )

                # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
                fig1.update_layout(
                    title_text="ì›”ë³„ ìˆ˜ì…ëŸ‰ê³¼ ê²€ìƒ‰ëŸ‰ ì¶”ì´",
                    legend=dict(
                        orientation="h",
                        yanchor="bottom",
                        y=1.02,
                        xanchor="right",
                        x=1
                    )
                )

                # Yì¶• ë¼ë²¨ ì„¤ì •
                fig1.update_yaxes(title_text="<b>ìˆ˜ì…ëŸ‰ (kg)</b>", secondary_y=False)
                fig1.update_yaxes(title_text="<b>ê²€ìƒ‰ëŸ‰</b>", secondary_y=True)

                st.plotly_chart(fig1, use_container_width=True)

                # -------------------------
                # ì›ì‚°ì§€ë³„ ê°€ê²© ê²½ìŸë ¥ ë° ê³µê¸‰ ì•ˆì •ì„± ë¶„ì„
                # -------------------------
                st.subheader("ì›ì‚°ì§€ë³„ ê°€ê²© ê²½ìŸë ¥ ë° ê³µê¸‰ ì•ˆì •ì„± ë¶„ì„")
                
                # TDSì™€ ê´€ì„¸ì²­ ë°ì´í„° í†µí•©
                df_country_analysis = df_combined_imports_tds.copy()
                df_country_analysis.rename(columns={'Volume': 'ìˆ˜ì… ì¤‘ëŸ‰', 'Value': 'ìˆ˜ì… ê¸ˆì•¡'}, inplace=True)
                df_country_analysis['ë‹¨ê°€'] = df_country_analysis['ìˆ˜ì… ê¸ˆì•¡'] / df_country_analysis['ìˆ˜ì… ì¤‘ëŸ‰']
                df_country_analysis.dropna(subset=['ë‹¨ê°€', 'Origin Country'], inplace=True)

                if not df_country_analysis.empty:
                    col_price, col_stability = st.columns(2)

                    with col_price:
                        # ê°€ê²© ê²½ìŸë ¥ (í‰ê·  ë‹¨ê°€)
                        price_competitiveness = df_country_analysis.groupby('Origin Country')['ë‹¨ê°€'].mean().reset_index()
                        price_competitiveness = price_competitiveness.sort_values(by='ë‹¨ê°€', ascending=True)
                        fig_price = px.bar(
                            price_competitiveness.head(10),
                            x='Origin Country',
                            y='ë‹¨ê°€',
                            title='í‰ê·  ë‹¨ê°€($/kg) - ê°€ê²© ê²½ìŸë ¥ (ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬)',
                            labels={'ë‹¨ê°€': 'í‰ê·  ë‹¨ê°€ ($/kg)', 'Origin Country': 'ì›ì‚°ì§€'}
                        )
                        st.plotly_chart(fig_price, use_container_width=True)

                    with col_stability:
                        # ê³µê¸‰ ì•ˆì •ì„± (ìˆ˜ì… ì¤‘ëŸ‰ ë³€ë™ì„±)
                        monthly_volume = df_country_analysis.groupby([pd.Grouper(key='Date', freq='M'), 'Origin Country'])['ìˆ˜ì… ì¤‘ëŸ‰'].sum().reset_index()
                        stability = monthly_volume.groupby('Origin Country')['ìˆ˜ì… ì¤‘ëŸ‰'].std().reset_index().rename(columns={'ìˆ˜ì… ì¤‘ëŸ‰': 'ë³€ë™ì„±'})
                        stability = stability.sort_values(by='ë³€ë™ì„±', ascending=True)
                        fig_stability = px.bar(
                            stability.head(10),
                            x='Origin Country',
                            y='ë³€ë™ì„±',
                            title='ê³µê¸‰ëŸ‰ ë³€ë™ì„± (ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì )',
                            labels={'ë³€ë™ì„±': 'í‘œì¤€í¸ì°¨', 'Origin Country': 'ì›ì‚°ì§€'}
                        )
                        st.plotly_chart(fig_stability, use_container_width=True)
                else:
                    st.warning("ì„ íƒí•œ HSì½”ë“œì— ëŒ€í•œ ì›ì‚°ì§€ë³„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ë¶„ì„ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # êµ­ê°€ë³„ ìˆ˜ì…ëŸ‰/ê¸ˆì•¡ ê·¸ë˜í”„
                st.subheader("êµ­ê°€ë³„ ìˆ˜ì…ëŸ‰ ë° ê¸ˆì•¡")
                
                df_imports_country = st.session_state.df_imports[
                    st.session_state.df_imports['HSì½”ë“œ'].astype(str).isin(selected_codes)
                ].groupby('êµ­ê°€').agg({
                    'ìˆ˜ì… ì¤‘ëŸ‰': 'sum',
                    'ìˆ˜ì… ê¸ˆì•¡': 'sum'
                }).reset_index()
                
                df_tds_country = st.session_state.df_tds[
                    st.session_state.df_tds['HSì½”ë“œ'].astype(str).isin(selected_codes)
                ].groupby('Origin Country').agg({
                    'Volume': 'sum',
                    'Value': 'sum'
                }).reset_index().rename(columns={'Origin Country': 'êµ­ê°€', 'Volume': 'ìˆ˜ì… ì¤‘ëŸ‰', 'Value': 'ìˆ˜ì… ê¸ˆì•¡'})
                
                df_country = pd.concat([df_imports_country, df_tds_country]).groupby('êµ­ê°€').sum().reset_index()
                df_country = df_country.sort_values(by='ìˆ˜ì… ì¤‘ëŸ‰', ascending=False)
                
                if not df_country.empty:
                    col1_bar, col2_bar = st.columns(2)
                    with col1_bar:
                        fig_country_vol = px.bar(
                            df_country.head(10), 
                            x='êµ­ê°€', 
                            y='ìˆ˜ì… ì¤‘ëŸ‰', 
                            title='ì£¼ìš” ìˆ˜ì…êµ­ (ìˆ˜ì…ëŸ‰ ê¸°ì¤€)',
                            labels={'ìˆ˜ì… ì¤‘ëŸ‰': 'ìˆ˜ì…ëŸ‰ (kg)'}
                        )
                        st.plotly_chart(fig_country_vol, use_container_width=True)
                    with col2_bar:
                        fig_country_val = px.bar(
                            df_country.sort_values(by='ìˆ˜ì… ê¸ˆì•¡', ascending=False).head(10), 
                            x='êµ­ê°€', 
                            y='ìˆ˜ì… ê¸ˆì•¡', 
                            title='ì£¼ìš” ìˆ˜ì…êµ­ (ìˆ˜ì…ê¸ˆì•¡ ê¸°ì¤€)',
                            labels={'ìˆ˜ì… ê¸ˆì•¡': 'ìˆ˜ì…ê¸ˆì•¡ ($)'}
                        )
                        st.plotly_chart(fig_country_val, use_container_chart=True)
                else:
                    st.warning("ì„ íƒí•œ HSì½”ë“œì— ëŒ€í•œ êµ­ê°€ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ì„ íƒí•œ HSì½”ë“œì— ëŒ€í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ëŒ€ì‹œë³´ë“œë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        with tab2:
            st.header("ìˆ˜ìš”/ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ (ê°„ë‹¨í•œ íšŒê·€ ëª¨ë¸)")
            st.markdown("""
            ---
            ### **ì˜ˆì¸¡ ë¡œì§ ì„¤ëª…**
            ì´ ëª¨ë¸ì€ **ë‹¨ìˆœ ì„ í˜• íšŒê·€(Linear Regression)**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê³¼ê±° **'ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰'** ë°ì´í„°ê°€ ë‹¤ìŒ ë‹¬ **'ìˆ˜ì… ì¤‘ëŸ‰'**ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ì—¬ ë¯¸ë˜ì˜ ìˆ˜ì…ëŸ‰ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì¦‰, ì†Œë¹„ìì˜ ê²€ìƒ‰ ê´€ì‹¬ë„(ìˆ˜ìš”)ê°€ ì‹¤ì œ ìˆ˜ì…(ê³µê¸‰)ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²½í–¥ì„ íŒŒì•…í•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

            **ğŸ’¡ ì „ëµ ì¸ì‚¬ì´íŠ¸**: ê²€ìƒ‰ëŸ‰ì´ ìˆ˜ì…ëŸ‰ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëŸ‰ ì¶”ì´ë¥¼ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ë¯¸ë¦¬ ë¬¼ëŸ‰ì„ í™•ë³´í•˜ë©´ ì¬ê³  ë° ê³µê¸‰ë§ ê´€ë¦¬ì— ìœ ë¦¬í•©ë‹ˆë‹¤.
            """)
            
            if not st.session_state.df_combined.empty and not st.session_state.df_combined['ìˆ˜ì… ì¤‘ëŸ‰'].sum() == 0:
                df_model = st.session_state.df_combined.copy()
                
                df_model['ê²€ìƒ‰ëŸ‰_lag1'] = df_model['ê²€ìƒ‰ëŸ‰'].shift(1)
                df_model.dropna(inplace=True)

                if not df_model.empty:
                    # statsmodelsë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ë¢°êµ¬ê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
                    X = sm.add_constant(df_model['ê²€ìƒ‰ëŸ‰_lag1'])
                    y = df_model['ìˆ˜ì… ì¤‘ëŸ‰']
                    
                    model = sm.OLS(y, X).fit()
                    
                    # ì˜ˆì¸¡ê°’ê³¼ 95% ì‹ ë¢°êµ¬ê°„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                    predictions = model.get_prediction(X)
                    df_model['ì˜ˆì¸¡ ìˆ˜ì… ì¤‘ëŸ‰'] = predictions.predicted_mean
                    conf_int = predictions.conf_int(alpha=0.05)
                    df_model['conf_int_lower'] = conf_int[:, 0]
                    df_model['conf_int_upper'] = conf_int[:, 1]
                    
                    st.write("---")
                    st.subheader("ë¯¸ë˜ ìˆ˜ì…ëŸ‰ ì˜ˆì¸¡")
                    
                    last_search_volume = df_model['ê²€ìƒ‰ëŸ‰'].iloc[-1]
                    predicted_volume = model.predict([1, last_search_volume])[0]
                    
                    st.success(f"ë‹¤ìŒ ë‹¬ ì˜ˆìƒ ìˆ˜ì…ëŸ‰ì€ **{predicted_volume:,.0f} kg** ì…ë‹ˆë‹¤.")
                    st.info("ğŸ’¡ **ì „ëµ ì¸ì‚¬ì´íŠ¸**: ê²€ìƒ‰ëŸ‰ì´ ìˆ˜ì…ëŸ‰ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëŸ‰ ì¶”ì´ë¥¼ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ë¯¸ë¦¬ ë¬¼ëŸ‰ì„ í™•ë³´í•˜ì„¸ìš”.")
            
                    st.subheader("ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼ ì‹œê°í™”")
                    fig_pred = go.Figure()

                    # ì‹¤ì œ ìˆ˜ì…ëŸ‰
                    fig_pred.add_trace(go.Scatter(
                        x=df_model['ê¸°ê°„'],
                        y=df_model['ìˆ˜ì… ì¤‘ëŸ‰'],
                        mode='lines',
                        name='ì‹¤ì œ ìˆ˜ì… ì¤‘ëŸ‰'
                    ))

                    # ì˜ˆì¸¡ ìˆ˜ì…ëŸ‰
                    fig_pred.add_trace(go.Scatter(
                        x=df_model['ê¸°ê°„'],
                        y=df_model['ì˜ˆì¸¡ ìˆ˜ì… ì¤‘ëŸ‰'],
                        mode='lines',
                        name='ì˜ˆì¸¡ ìˆ˜ì… ì¤‘ëŸ‰',
                        line=dict(color='red', dash='dash')
                    ))

                    # ì‹ ë¢°êµ¬ê°„ (ìŒì˜)
                    fig_pred.add_trace(go.Scatter(
                        x=df_model['ê¸°ê°„'],
                        y=df_model['conf_int_upper'],
                        mode='lines',
                        line=dict(width=0),
                        showlegend=False
                    ))
                    fig_pred.add_trace(go.Scatter(
                        x=df_model['ê¸°ê°„'],
                        y=df_model['conf_int_lower'],
                        mode='lines',
                        line=dict(width=0),
                        fill='tonexty',
                        fillcolor='rgba(200, 200, 200, 0.2)',
                        name='95% ì‹ ë¢°êµ¬ê°„'
                    ))

                    fig_pred.update_layout(
                        title_text="ì‹¤ì œ ìˆ˜ì…ëŸ‰ vs. ì˜ˆì¸¡ ìˆ˜ì…ëŸ‰ (95% ì‹ ë¢°êµ¬ê°„)",
                        xaxis_title="ê¸°ê°„",
                        yaxis_title="ìˆ˜ì…ëŸ‰ (kg)"
                    )
                    st.plotly_chart(fig_pred, use_container_width=True)
                else:
                    st.warning("ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ ì˜ˆì¸¡ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            else:
                st.warning("ì„ íƒí•œ HSì½”ë“œì— ëŒ€í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì˜ˆì¸¡ ëª¨ë¸ì„ í™œì„±í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        with tab3:
            st.header("ë°ì´í„° ìƒê´€ê´€ê³„ ë¶„ì„")
            if not st.session_state.df_combined.empty and not st.session_state.df_combined['ìˆ˜ì… ì¤‘ëŸ‰'].sum() == 0:
                corr_matrix = st.session_state.df_combined[['ìˆ˜ì… ì¤‘ëŸ‰', 'ìˆ˜ì… ê¸ˆì•¡', 'ê²€ìƒ‰ëŸ‰']].corr()
                st.subheader("ìƒê´€ê´€ê³„ í–‰ë ¬")
                st.dataframe(corr_matrix, use_container_width=True)

                st.markdown(
                    """
                    - **ìƒê´€ê³„ìˆ˜ 1**: ì™„ë²½í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ (í•œ ë³€ìˆ˜ ì¦ê°€ ì‹œ ë‹¤ë¥¸ ë³€ìˆ˜ë„ ì¦ê°€)
                    - **ìƒê´€ê³„ìˆ˜ -1**: ì™„ë²½í•œ ìŒì˜ ìƒê´€ê´€ê³„ (í•œ ë³€ìˆ˜ ì¦ê°€ ì‹œ ë‹¤ë¥¸ ë³€ìˆ˜ëŠ” ê°ì†Œ)
                    - **ìƒê´€ê³„ìˆ˜ 0**: ìƒê´€ê´€ê³„ ì—†ìŒ
                    """
                )
                
                st.write("---")
                st.subheader("ì‚°ì ë„ ì‹œê°í™”")
                fig_scatter = px.scatter(
                    st.session_state.df_combined,
                    x='ê²€ìƒ‰ëŸ‰',
                    y='ìˆ˜ì… ì¤‘ëŸ‰',
                    trendline='ols',
                    title='ê²€ìƒ‰ëŸ‰ê³¼ ìˆ˜ì…ëŸ‰ì˜ ìƒê´€ê´€ê³„',
                    labels={'ê²€ìƒ‰ëŸ‰': 'ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰', 'ìˆ˜ì… ì¤‘ëŸ‰': 'ìˆ˜ì…ëŸ‰ (kg)'}
                )
                st.plotly_chart(fig_scatter, use_container_width=True)

                st.info("ğŸ’¡ **ì¸ì‚¬ì´íŠ¸**: ê²€ìƒ‰ëŸ‰ê³¼ ìˆ˜ì…ëŸ‰ ê°„ì˜ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ë³´ì¸ë‹¤ë©´, ê²€ìƒ‰ëŸ‰ ì¦ê°€ëŠ” ë¯¸ë˜ì˜ ìˆ˜ìš” ì¦ê°€ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìˆ˜ì… ë¬¼ëŸ‰ ê²°ì •ì— ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ì„ íƒí•œ HSì½”ë“œì— ëŒ€í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒê´€ê´€ê³„ ë¶„ì„ì„ í™œì„±í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        with tab4:
            st.header("ì›ë³¸ ë°ì´í„°")
            st.subheader("ê´€ì„¸ì²­ ë°ì´í„°")
            st.dataframe(st.session_state.df_imports, use_container_width=True)
            st.subheader("ë„¤ì´ë²„ ë°ì´í„°ë© ê²€ìƒ‰ëŸ‰")
            st.dataframe(st.session_state.df_naver, use_container_width=True)
            st.subheader("TDS ë°ì´í„°")
            st.dataframe(st.session_state.df_tds, use_container_width=True)
