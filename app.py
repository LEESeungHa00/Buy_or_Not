import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.linear_model import LinearRegression
import io
from datetime import datetime, timedelta

# êµ¬ê¸€ ì‹œíŠ¸ API ì—°ë™ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import gspread
from google.oauth2 import service_account

# ì„¤ì •: í˜ì´ì§€ ì œëª© ë° ë ˆì´ì•„ì›ƒ
st.set_page_config(
    page_title="Data-Driven_Direction",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'df_imports' not in st.session_state:
    st.session_state.df_imports = pd.DataFrame()
if 'df_naver' not in st.session_state:
    st.session_state.df_naver = pd.DataFrame()
if 'df_tds' not in st.session_state:
    st.session_state.df_tds = pd.DataFrame()
if 'df_combined' not in st.session_state:
    st.session_state.df_combined = pd.DataFrame()
if 'selected_hscodes' not in st.session_state:
    st.session_state.selected_hscodes = []

st.title("ğŸ§­ Compass : Data-Driven Direction")

st.markdown("""
<style>
.stTabs [data-baseweb="tab-list"] button [data-testid="stMarkdownContainer"] p {
    font-size: 1.2rem;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)

# -----------------
# êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ í•¨ìˆ˜
# -----------------
@st.cache_resource(ttl=3600)
def get_google_sheet_client():
    """
    Streamlit secretsë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ê¸€ ì‹œíŠ¸ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¸ì¦í•˜ê³  ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    ì‹¤ì œ Streamlit Cloud í™˜ê²½ì—ì„œ secretsì— ì„œë¹„ìŠ¤ ê³„ì • JSONì´ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨.
    """
    try:
        credentials = service_account.Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=["https://www.googleapis.com/auth/spreadsheets"]
        )
        gc = gspread.authorize(credentials)
        return gc
    except Exception as e:
        st.error(f"êµ¬ê¸€ ì‹œíŠ¸ ì¸ì¦ ì˜¤ë¥˜: {e}")
        return None

def read_google_sheet(sheet_name):
    """
    ì§€ì •ëœ êµ¬ê¸€ ì‹œíŠ¸ì˜ ì›Œí¬ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    gc = get_google_sheet_client()
    if gc:
        try:
            sh = gc.open_by_url("https://docs.google.com/spreadsheets/d/12YdcKX3nvaNfFWYkJApRnoKAQnjCeR09AGRJ6rBiOuM/edit?gid=0#gid=0")
            worksheet = sh.worksheet(sheet_name)
            
            all_data = worksheet.get_all_values()
            if not all_data:
                return pd.DataFrame()
            
            headers = all_data[0]
            seen = {}
            for i, header in enumerate(headers):
                if not header:
                    headers[i] = f'Unnamed_{i}'
                elif header in seen:
                    headers[i] = f'{header}_{seen[header]}'
                    seen[header] += 1
                else:
                    seen[header] = 1

            data = all_data[1:]
            df = pd.DataFrame(data, columns=headers)
            
            # ë°ì´í„° ì •ì œ ë° íƒ€ì… ë³€í™˜
            if sheet_name == 'ë„¤ì´ë²„ ë°ì´í„°ë©':
                if 'ì»¤í”¼' in df.columns:
                    df.rename(columns={'ì»¤í”¼': 'ê²€ìƒ‰ëŸ‰'}, inplace=True)
                df['ê²€ìƒ‰ëŸ‰'] = pd.to_numeric(df['ê²€ìƒ‰ëŸ‰'], errors='coerce')
            elif sheet_name == 'TDS':
                if 'Detailed HS-CODE' in df.columns:
                    df.rename(columns={'Detailed HS-CODE': 'HSì½”ë“œ'}, inplace=True)
                df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')
                df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
            elif sheet_name == 'ê´€ì„¸ì²­':
                df['ìˆ˜ì… ì¤‘ëŸ‰'] = pd.to_numeric(df['ìˆ˜ì… ì¤‘ëŸ‰'], errors='coerce')
                df['ìˆ˜ì… ê¸ˆì•¡'] = pd.to_numeric(df['ìˆ˜ì… ê¸ˆì•¡'], errors='coerce')

            return df
        except Exception as e:
            st.error(f"'{sheet_name}' ì›Œí¬ì‹œíŠ¸ ì½ê¸° ì˜¤ë¥˜: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

# -----------------
# íŒŒì¼ ì—…ë¡œë“œ ë° ë°ì´í„° ì²˜ë¦¬
# -----------------
st.sidebar.header("ë°ì´í„° ì—…ë¡œë“œ ë° ê°€ì ¸ì˜¤ê¸°")
uploaded_imports = st.sidebar.file_uploader("1. ê´€ì„¸ì²­ ë°ì´í„° (.csv)", type="csv", key="imports")
uploaded_naver = st.sidebar.file_uploader("2. ë„¤ì´ë²„ ë°ì´í„°ë© (.csv)", type="csv", key="naver")
uploaded_tds = st.sidebar.file_uploader("3. íŠ¸ë¦¿ì§€ ë°ì´í„° (.csv)", type="csv", key="tds")

def load_data():
    if uploaded_imports:
        try:
            df = pd.read_csv(uploaded_imports)
            if 'ê¸°ê°„' not in df.columns:
                if 'ë…„' in df.columns and 'ì›”' in df.columns:
                    df['ê¸°ê°„'] = df['ë…„'].astype(str) + '.' + df['ì›”'].astype(str).str.zfill(2)
            # ìˆ˜ì…ëŸ‰, ìˆ˜ì…ê¸ˆì•¡ ìˆ«ìí˜• ë³€í™˜
            df['ìˆ˜ì… ì¤‘ëŸ‰'] = pd.to_numeric(df['ìˆ˜ì… ì¤‘ëŸ‰'], errors='coerce')
            df['ìˆ˜ì… ê¸ˆì•¡'] = pd.to_numeric(df['ìˆ˜ì… ê¸ˆì•¡'], errors='coerce')
            st.session_state.df_imports = pd.concat([st.session_state.df_imports, df], ignore_index=True)
            st.sidebar.success("ê´€ì„¸ì²­ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            st.sidebar.error(f"ê´€ì„¸ì²­ CSV íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")

    if uploaded_naver:
        try:
            df = pd.read_csv(uploaded_naver, skiprows=6)
            df.columns = ['ë‚ ì§œ', 'ê²€ìƒ‰ëŸ‰']
            # ê²€ìƒ‰ëŸ‰ ì»¬ëŸ¼ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
            df['ê²€ìƒ‰ëŸ‰'] = pd.to_numeric(df['ê²€ìƒ‰ëŸ‰'], errors='coerce')
            st.session_state.df_naver = pd.concat([st.session_state.df_naver, df], ignore_index=True)
            st.sidebar.success("ë„¤ì´ë²„ ë°ì´í„°ë© ì—…ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            st.sidebar.error(f"ë„¤ì´ë²„ ë°ì´í„°ë© CSV íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")

    if uploaded_tds:
        try:
            df_raw = uploaded_tds.getvalue().decode("utf-8")
            df = pd.read_csv(io.StringIO(df_raw), header=None)
            
            headers = df.iloc[0].tolist()
            seen = {}
            new_headers = []
            for i, header in enumerate(headers):
                if not isinstance(header, str) or not header:
                    new_header = f'Unnamed_{i}'
                elif header in seen:
                    seen[header] += 1
                    new_header = f'{header}_{seen[header]}'
                else:
                    seen[header] = 1
                    new_header = header
                new_headers.append(new_header)
            
            df.columns = new_headers
            df = df.iloc[1:].reset_index(drop=True)
            
            # TDS ë°ì´í„°ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë³€í™˜
            if 'Detailed HS-CODE' in df.columns:
                df.rename(columns={'Detailed HS-CODE': 'HSì½”ë“œ'}, inplace=True)
            if 'Volume' in df.columns:
                df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')
            if 'Value' in df.columns:
                df['Value'] = pd.to_numeric(df['Value'], errors='coerce')

            st.session_state.df_tds = pd.concat([st.session_state.df_tds, df], ignore_index=True)
            st.sidebar.success("TDS ì—…ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            st.sidebar.error(f"TDS CSV íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")

if st.sidebar.button("ë°ì´í„° ì—…ë¡œë“œ ë° ê°€ì ¸ì˜¤ê¸°"):
    load_data()
    st.session_state.df_imports = read_google_sheet("ê´€ì„¸ì²­")
    st.session_state.df_naver = read_google_sheet("ë„¤ì´ë²„ ë°ì´í„°ë©")
    st.session_state.df_tds = read_google_sheet("TDS")
    if not st.session_state.df_imports.empty: st.sidebar.success("ê´€ì„¸ì²­ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
    if not st.session_state.df_naver.empty: st.sidebar.success("ë„¤ì´ë²„ ë°ì´í„°ë© ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
    if not st.session_state.df_tds.empty: st.sidebar.success("TDS ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")

if st.session_state.df_imports.empty or st.session_state.df_tds.empty or st.session_state.df_naver.empty:
    st.warning("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ **ë°ì´í„° ì—…ë¡œë“œ ë° ê°€ì ¸ì˜¤ê¸°** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
else:
    all_hscodes = pd.concat([
        st.session_state.df_imports[['HSì½”ë“œ', 'í’ˆëª©ëª…']],
        st.session_state.df_tds.rename(columns={'Product Description': 'í’ˆëª©ëª…'})[['HSì½”ë“œ', 'í’ˆëª©ëª…']]
    ]).drop_duplicates(subset='HSì½”ë“œ').sort_values(by='HSì½”ë“œ').reset_index(drop=True)
    
    hscode_options = [f"{row['HSì½”ë“œ']} - {row['í’ˆëª©ëª…']}" for index, row in all_hscodes.iterrows()]
    st.session_state.selected_hscodes = st.sidebar.multiselect(
        "ë¶„ì„í•  HSì½”ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=hscode_options,
        default=hscode_options[:2] if len(hscode_options) > 1 else hscode_options
    )

    selected_codes = [s.split(' - ')[0] for s in st.session_state.selected_hscodes]

    if not selected_codes:
        st.warning("ë¶„ì„ì„ ìœ„í•´ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ HSì½”ë“œë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        with st.spinner('ë°ì´í„°ë¥¼ í†µí•©í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            try:
                # ê´€ì„¸ì²­ ë°ì´í„° í•„í„°ë§ ë° ì „ì²˜ë¦¬
                df_imports_filtered = st.session_state.df_imports[
                    st.session_state.df_imports['HSì½”ë“œ'].astype(str).isin(selected_codes)
                ].copy()
                df_imports_filtered['ê¸°ê°„'] = pd.to_datetime(df_imports_filtered['ê¸°ê°„'], format='%Y.%m', errors='coerce')
                df_imports_filtered.dropna(subset=['ê¸°ê°„'], inplace=True)
                df_imports_monthly = df_imports_filtered.groupby(
                    pd.Grouper(key='ê¸°ê°„', freq='M')
                ).agg({
                    'ìˆ˜ì… ì¤‘ëŸ‰': 'sum',
                    'ìˆ˜ì… ê¸ˆì•¡': 'sum'
                }).reset_index()

                # ë„¤ì´ë²„ ë°ì´í„°ë© ë°ì´í„° ì „ì²˜ë¦¬
                df_naver_monthly = st.session_state.df_naver.copy()
                df_naver_monthly['ë‚ ì§œ'] = pd.to_datetime(df_naver_monthly['ë‚ ì§œ'], errors='coerce')
                df_naver_monthly.dropna(subset=['ë‚ ì§œ'], inplace=True)
                df_naver_monthly = df_naver_monthly.groupby(
                    pd.Grouper(key='ë‚ ì§œ', freq='M')
                ).agg(
                    {'ê²€ìƒ‰ëŸ‰': 'mean'}
                ).reset_index()
                
                # ìµœì¢… ë°ì´í„° ë³‘í•© (how='inner'ë¥¼ 'how='outer'ë¡œ ë³€ê²½)
                st.session_state.df_combined = pd.merge(
                    df_imports_monthly, 
                    df_naver_monthly, 
                    left_on=df_imports_monthly['ê¸°ê°„'].dt.strftime('%Y-%m'), 
                    right_on=df_naver_monthly['ë‚ ì§œ'].dt.strftime('%Y-%m'),
                    how='outer'
                )
                
                # ë³‘í•© í›„ NaN ê°’ 0ìœ¼ë¡œ ì±„ìš°ê³  ì»¬ëŸ¼ëª… ì •ë¦¬
                st.session_state.df_combined.rename(columns={'key_0': 'ê¸°ê°„', 'ë‚ ì§œ': 'ë„¤ì´ë²„ ë‚ ì§œ'}, inplace=True)
                
                # ê¸°ê°„ ì»¬ëŸ¼ì„ í•©ì¹˜ê¸°
                st.session_state.df_combined['ê¸°ê°„'] = st.session_state.df_combined['ê¸°ê°„'].fillna(st.session_state.df_combined['ë„¤ì´ë²„ ë‚ ì§œ'].dt.strftime('%Y-%m'))
                st.session_state.df_combined.drop('ë„¤ì´ë²„ ë‚ ì§œ', axis=1, inplace=True)

                st.session_state.df_combined['ìˆ˜ì… ì¤‘ëŸ‰'].fillna(0, inplace=True)
                st.session_state.df_combined['ìˆ˜ì… ê¸ˆì•¡'].fillna(0, inplace=True)
                st.session_state.df_combined['ê²€ìƒ‰ëŸ‰'].fillna(0, inplace=True)

                st.success("ë°ì´í„° í†µí•© ì™„ë£Œ!")
            except Exception as e:
                st.error(f"ë°ì´í„° í†µí•© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì„ íƒí•œ HSì½”ë“œì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ê±°ë‚˜, ì—…ë¡œë“œí•œ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”: {e}")

        # -----------------
        # íƒ­ êµ¬ì„±
        # -----------------
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ”® ì˜ˆì¸¡ ëª¨ë¸", "ğŸ“ˆ ìƒê´€ê´€ê³„ ë¶„ì„", "ğŸ—ƒï¸ ì›ë³¸ ë°ì´í„°"])

        with tab1:
            st.header("ì»¤í”¼ ì›ë‘ ì‹œì¥ ë™í–¥ ë¶„ì„")
            if not st.session_state.df_combined.empty:
                # KPI ì§€í‘œ
                col1, col2, col3 = st.columns(3)
                with col1:
                    total_volume = st.session_state.df_combined['ìˆ˜ì… ì¤‘ëŸ‰'].sum() / 1000000
                    st.metric("ì´ ìˆ˜ì…ëŸ‰ (ë°±ë§Œ kg)", f"{total_volume:,.2f}")
                with col2:
                    total_value = st.session_state.df_combined['ìˆ˜ì… ê¸ˆì•¡'].sum() / 1000000
                    st.metric("ì´ ìˆ˜ì…ê¸ˆì•¡ (ë°±ë§Œ $)", f"{total_value:,.2f}")
                with col3:
                    # 'ìˆ˜ì… ì¤‘ëŸ‰'ì´ 0ì¸ ê²½ìš°ë¥¼ ë°©ì§€
                    valid_data = st.session_state.df_combined[st.session_state.df_combined['ìˆ˜ì… ì¤‘ëŸ‰'] > 0]
                    avg_unit_price = (valid_data['ìˆ˜ì… ê¸ˆì•¡'] / valid_data['ìˆ˜ì… ì¤‘ëŸ‰']).mean()
                    st.metric("í‰ê·  ë‹¨ê°€ ($/kg)", f"{avg_unit_price:,.2f}" if not pd.isna(avg_unit_price) else "N/A")

                # ê·¸ë˜í”„: ìˆ˜ì…ëŸ‰, ìˆ˜ì…ê¸ˆì•¡, ê²€ìƒ‰ëŸ‰
                st.subheader("ê¸°ê°„ë³„ ìˆ˜ì…ëŸ‰ ë° ê²€ìƒ‰ëŸ‰ ì¶”ì´")
                fig1 = px.line(
                    st.session_state.df_combined, 
                    x="ê¸°ê°„", 
                    y=["ìˆ˜ì… ì¤‘ëŸ‰", "ê²€ìƒ‰ëŸ‰"], 
                    labels={"value": "ìˆ˜ëŸ‰ / ê²€ìƒ‰ëŸ‰", "variable": "ì§€í‘œ"},
                    title="ì›”ë³„ ìˆ˜ì…ëŸ‰ê³¼ ê²€ìƒ‰ëŸ‰ ì¶”ì´"
                )
                fig1.update_traces(hovertemplate="%{x|%Y-%m}<br>%{y:,.0f}")
                st.plotly_chart(fig1, use_container_width=True)

                # êµ­ê°€ë³„ ìˆ˜ì…ëŸ‰/ê¸ˆì•¡ ê·¸ë˜í”„
                st.subheader("êµ­ê°€ë³„ ìˆ˜ì…ëŸ‰ ë° ê¸ˆì•¡")
                df_imports_country = st.session_state.df_imports[
                    st.session_state.df_imports['HSì½”ë“œ'].astype(str).isin(selected_codes)
                ].groupby('êµ­ê°€').agg({
                    'ìˆ˜ì… ì¤‘ëŸ‰': 'sum',
                    'ìˆ˜ì… ê¸ˆì•¡': 'sum'
                }).reset_index()
                
                df_tds_country = st.session_state.df_tds[
                    st.session_state.df_tds['HSì½”ë“œ'].astype(str).isin(selected_codes)
                ].groupby('Origin Country').agg({
                    'Volume': 'sum',
                    'Value': 'sum'
                }).reset_index().rename(columns={'Origin Country': 'êµ­ê°€', 'Volume': 'ìˆ˜ì… ì¤‘ëŸ‰', 'Value': 'ìˆ˜ì… ê¸ˆì•¡'})
                
                df_country = pd.concat([df_imports_country, df_tds_country]).groupby('êµ­ê°€').sum().reset_index()
                df_country = df_country.sort_values(by='ìˆ˜ì… ì¤‘ëŸ‰', ascending=False)

                col1_bar, col2_bar = st.columns(2)
                with col1_bar:
                    fig_country_vol = px.bar(
                        df_country.head(10), 
                        x='êµ­ê°€', 
                        y='ìˆ˜ì… ì¤‘ëŸ‰', 
                        title='ì£¼ìš” ìˆ˜ì…êµ­ (ìˆ˜ì…ëŸ‰ ê¸°ì¤€)',
                        labels={'ìˆ˜ì… ì¤‘ëŸ‰': 'ìˆ˜ì…ëŸ‰ (kg)'}
                    )
                    st.plotly_chart(fig_country_vol, use_container_width=True)
                with col2_bar:
                    fig_country_val = px.bar(
                        df_country.sort_values(by='ìˆ˜ì… ê¸ˆì•¡', ascending=False).head(10), 
                        x='êµ­ê°€', 
                        y='ìˆ˜ì… ê¸ˆì•¡', 
                        title='ì£¼ìš” ìˆ˜ì…êµ­ (ìˆ˜ì…ê¸ˆì•¡ ê¸°ì¤€)',
                        labels={'ìˆ˜ì… ê¸ˆì•¡': 'ìˆ˜ì…ê¸ˆì•¡ ($)'}
                    )
                    st.plotly_chart(fig_country_val, use_container_chart=True)
            else:
                st.warning("ë°ì´í„° í†µí•©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ HSì½”ë“œê°€ í¬í•¨ëœ ë°ì´í„°ë¥¼ ì„ íƒí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

        with tab2:
            st.header("ìˆ˜ìš”/ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ (ê°„ë‹¨í•œ íšŒê·€ ëª¨ë¸)")
            if not st.session_state.df_combined.empty:
                df_model = st.session_state.df_combined.copy()
                
                df_model['ê²€ìƒ‰ëŸ‰_lag1'] = df_model['ê²€ìƒ‰ëŸ‰'].shift(1)
                df_model.dropna(inplace=True)

                if not df_model.empty:
                    model = LinearRegression()
                    X = df_model[['ê²€ìƒ‰ëŸ‰_lag1']]
                    y = df_model['ìˆ˜ì… ì¤‘ëŸ‰']
                    
                    model.fit(X, y)
                    df_model['ì˜ˆì¸¡ ìˆ˜ì… ì¤‘ëŸ‰'] = model.predict(X)
                    
                    st.write("---")
                    st.subheader("ë¯¸ë˜ ìˆ˜ì…ëŸ‰ ì˜ˆì¸¡")
                    
                    last_search_volume = df_model['ê²€ìƒ‰ëŸ‰'].iloc[-1]
                    predicted_volume = model.predict([[last_search_volume]])[0]
                    
                    st.success(f"ë‹¤ìŒ ë‹¬ ì˜ˆìƒ ìˆ˜ì…ëŸ‰ì€ **{predicted_volume:,.0f} kg** ì…ë‹ˆë‹¤.")
                    st.info("ğŸ’¡ **ì „ëµ ì¸ì‚¬ì´íŠ¸**: ê²€ìƒ‰ëŸ‰ì´ ìˆ˜ì…ëŸ‰ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëŸ‰ ì¶”ì´ë¥¼ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ë¯¸ë¦¬ ë¬¼ëŸ‰ì„ í™•ë³´í•˜ì„¸ìš”.")
            
                    st.subheader("ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼ ì‹œê°í™”")
                    fig_pred = px.line(
                        df_model, 
                        x='ê¸°ê°„', 
                        y=['ìˆ˜ì… ì¤‘ëŸ‰', 'ì˜ˆì¸¡ ìˆ˜ì… ì¤‘ëŸ‰'],
                        title='ì‹¤ì œ ìˆ˜ì…ëŸ‰ vs. ì˜ˆì¸¡ ìˆ˜ì…ëŸ‰',
                        labels={'value': 'ìˆ˜ì…ëŸ‰ (kg)', 'variable': 'ì§€í‘œ'}
                    )
                    fig_pred.update_traces(hovertemplate="%{x|%Y-%m}<br>%{y:,.0f}")
                    st.plotly_chart(fig_pred, use_container_width=True)
                else:
                    st.warning("ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ ì˜ˆì¸¡ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            else:
                st.warning("ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ì½ì–´ì™€ ì˜ˆì¸¡ ëª¨ë¸ì„ í™œì„±í™”í•˜ì„¸ìš”. HSì½”ë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

        with tab3:
            st.header("ë°ì´í„° ìƒê´€ê´€ê³„ ë¶„ì„")
            if not st.session_state.df_combined.empty:
                corr_matrix = st.session_state.df_combined[['ìˆ˜ì… ì¤‘ëŸ‰', 'ìˆ˜ì… ê¸ˆì•¡', 'ê²€ìƒ‰ëŸ‰']].corr()
                st.subheader("ìƒê´€ê´€ê³„ í–‰ë ¬")
                st.dataframe(corr_matrix.style.background_gradient(cmap='Blues'), use_container_width=True)

                st.markdown(
                    """
                    - **ìƒê´€ê³„ìˆ˜ 1**: ì™„ë²½í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ (í•œ ë³€ìˆ˜ ì¦ê°€ ì‹œ ë‹¤ë¥¸ ë³€ìˆ˜ë„ ì¦ê°€)
                    - **ìƒê´€ê³„ìˆ˜ -1**: ì™„ë²½í•œ ìŒì˜ ìƒê´€ê´€ê³„ (í•œ ë³€ìˆ˜ ì¦ê°€ ì‹œ ë‹¤ë¥¸ ë³€ìˆ˜ëŠ” ê°ì†Œ)
                    - **ìƒê´€ê³„ìˆ˜ 0**: ìƒê´€ê´€ê³„ ì—†ìŒ
                    """
                )
                
                st.write("---")
                st.subheader("ì‚°ì ë„ ì‹œê°í™”")
                fig_scatter = px.scatter(
                    st.session_state.df_combined,
                    x='ê²€ìƒ‰ëŸ‰',
                    y='ìˆ˜ì… ì¤‘ëŸ‰',
                    trendline='ols',
                    title='ê²€ìƒ‰ëŸ‰ê³¼ ìˆ˜ì…ëŸ‰ì˜ ìƒê´€ê´€ê³„',
                    labels={'ê²€ìƒ‰ëŸ‰': 'ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰', 'ìˆ˜ì… ì¤‘ëŸ‰': 'ìˆ˜ì…ëŸ‰ (kg)'}
                )
                st.plotly_chart(fig_scatter, use_container_width=True)

                st.info("ğŸ’¡ **ì¸ì‚¬ì´íŠ¸**: ê²€ìƒ‰ëŸ‰ê³¼ ìˆ˜ì…ëŸ‰ ê°„ì˜ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ë³´ì¸ë‹¤ë©´, ê²€ìƒ‰ëŸ‰ ì¦ê°€ëŠ” ë¯¸ë˜ì˜ ìˆ˜ìš” ì¦ê°€ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìˆ˜ì… ë¬¼ëŸ‰ ê²°ì •ì— ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ì½ì–´ì™€ ìƒê´€ê´€ê³„ ë¶„ì„ì„ í™œì„±í™”í•˜ì„¸ìš”. HSì½”ë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

        with tab4:
            st.header("ì›ë³¸ ë°ì´í„°")
            st.subheader("ê´€ì„¸ì²­ ë°ì´í„°")
            st.dataframe(st.session_state.df_imports, use_container_width=True)
            st.subheader("ë„¤ì´ë²„ ë°ì´í„°ë© ê²€ìƒ‰ëŸ‰")
            st.dataframe(st.session_state.df_naver, use_container_width=True)
            st.subheader("TDS ë°ì´í„°")
            st.dataframe(st.session_state.df_tds, use_container_width=True)
